# ğŸ” Anomaly Detection in Directed Energy Deposition (DED) Processes Using Thermal Images

**ENS 491-492 Graduation Project â€“ Group #121**

Berke AyyÄ±ldÄ±zlÄ± â€¢ Beyza Balota â€¢ Kerem Tatari  
Supervisors: Mustafa Ãœnel, Shawqi Mohammed Farea  
SabancÄ± University â€“ 2025

---

## ğŸ§  Overview

This project presents a **modular, interpretable machine learning framework** for detecting **porosity-related anomalies** in **Directed Energy Deposition (DED)** processes using **thermal imaging**.

We applied and compared **supervised**, **semi-supervised**, and **unsupervised** models on a real-world thermal dataset, addressing challenges like **high class imbalance**, **sparse annotations**, and **image noise**.

---

## ğŸ“ Project Structure

```bash
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ random_forest.py
â”‚   â”œâ”€â”€ xgboost_model.py
â”‚   â”œâ”€â”€ cnn_model.py
â”‚   â”œâ”€â”€ oneclass_svm.py
â”‚   â”œâ”€â”€ isolation_forest.py
â”‚   â”œâ”€â”€ autoencoder.py
â”‚   â””â”€â”€ dbscan.py
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ clean_data.py
â”‚   â”œâ”€â”€ extract_features.py
â”‚   â””â”€â”€ smote_balancing.py
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ confusion_matrices.png
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â””â”€â”€ metrics_summary.csv
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ ENS_492_Final_Report_Group_121.pdf
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“¸ Dataset

- **Source**: [Harvard Dataverse â€“ Thermal-Porosity Characterization Dataset](https://doi.org/10.7910/DVN/BWHYEH)
- **Material**: Tiâ€“6Alâ€“4V thin-walled structures
- **Process**: Laser Engineered Net Shaping (LENS)
- **Size**: Thousands of labeled thermal frames  
- **Defect Rate**: ~4.5% defective (highly imbalanced)

---

## ğŸ› ï¸ Methodology

### ğŸ”„ Preprocessing
- Header removal and missing value imputation
- Min-Max normalization ([0,1] scale)
- **Statistical feature extraction** (e.g., IQR, mean, std, quartiles)
- **Geometric feature extraction** (e.g., blob area, eccentricity)
- SMOTE oversampling for minority class balancing

### ğŸ§ª Models Implemented

| Category | Model | Features Used |
|---------|-------|----------------|
| **Supervised** | Random Forest, XGBoost | 11 statistical features |
|  | CNN | Raw image pixels |
| **Semi-Supervised** | One-Class SVM, Isolation Forest | Top 5 statistical features |
| **Unsupervised** | Autoencoder, DBSCAN | Raw images / top features |

---

## ğŸ“Š Results

### ğŸ”µ Supervised Models

| Model | Precision | Recall | F1-Score | Accuracy |
|-------|-----------|--------|----------|----------|
| **Random Forest** | 0.83 | **0.97** | **0.89** | 0.99 |
| **XGBoost** | 0.84 | 0.92 | 0.87 | 0.99 |
| **CNN** | **0.90** | 0.86 | 0.88 | 0.99 |

---

### ğŸŸ  Semi-Supervised Models

| Model | Precision | Recall | F1-Score | Accuracy |
|-------|-----------|--------|----------|----------|
| One-Class SVM | **0.85** | 0.66 | 0.75 | 0.98 |
| Isolation Forest | 0.75 | 0.75 | 0.75 | 0.98 |

---

### ğŸŸ£ Unsupervised Models

| Model | Precision | Recall | F1-Score | Accuracy |
|-------|-----------|--------|----------|----------|
| Autoencoder (95th pct.) | 0.54 | 0.61 | 0.57 | 0.96 |
| Autoencoder (99th pct.) | 0.75 | 0.17 | 0.28 | 0.96 |
| **DBSCAN** | 0.55 | **0.99** | **0.71** | 0.96 |

---

## ğŸ“ˆ Visualizations

- ğŸ“‰ Feature importance heatmaps (Random Forest, XGBoost)
- ğŸ“Š Confusion matrices for all models
- ğŸ” Correlation matrix of statistical features

---

## ğŸ’¡ Key Takeaways

- **Supervised models** (especially RF and CNN) offer best overall performance.
- **Semi-supervised models** are practical for low-label scenarios.
- **Unsupervised models** are flexible but require careful tuning.
- **Hybrid strategies** (e.g., using Autoencoders for early detection, then refining with supervised models) are recommended for industry settings.

---

## ğŸ“š References

- Dataset: [Harvard Dataverse - Tiâ€“6Alâ€“4V Thermal-Porosity Data](https://doi.org/10.7910/DVN/BWHYEH)
- [ASTM F2924 â€“ Additive Manufacturing for Ti-6Al-4V](https://www.astm.org/f2924-14r21.html)

---

## ğŸ§ª How to Run

```bash
pip install -r requirements.txt
python preprocessing/extract_features.py
python models/random_forest.py
```

---

## ğŸ‘¥ Authors

- **Berke AyyÄ±ldÄ±zlÄ±** â€“ Model Training, Feature Engineering  
- **Beyza Balota** â€“ CNN Development, Visualization  
- **Kerem Tatari** â€“ Unsupervised Models, Preprocessing

---

## ğŸ“„ License

Open for academic and research use. All models built using open-source libraries and ethically sourced datasets.
