{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Fold 1\n",
      "Accuracy: 0.9808\n",
      "Confusion Matrix:\n",
      "[[293   5]\n",
      " [  1  14]]\n",
      "Per-class Metrics:\n",
      "  Class 0: {'precision': 0.9966, 'recall': 0.9832, 'f1-score': 0.9899, 'support': 298}\n",
      "  Class 1: {'precision': 0.7368, 'recall': 0.9333, 'f1-score': 0.8235, 'support': 15}\n",
      "\n",
      "üîÅ Fold 2\n",
      "Accuracy: 0.9936\n",
      "Confusion Matrix:\n",
      "[[297   2]\n",
      " [  0  14]]\n",
      "Per-class Metrics:\n",
      "  Class 0: {'precision': 1.0, 'recall': 0.9933, 'f1-score': 0.9966, 'support': 299}\n",
      "  Class 1: {'precision': 0.875, 'recall': 1.0, 'f1-score': 0.9333, 'support': 14}\n",
      "\n",
      "üîÅ Fold 3\n",
      "Accuracy: 0.9808\n",
      "Confusion Matrix:\n",
      "[[293   6]\n",
      " [  0  14]]\n",
      "Per-class Metrics:\n",
      "  Class 0: {'precision': 1.0, 'recall': 0.9799, 'f1-score': 0.9899, 'support': 299}\n",
      "  Class 1: {'precision': 0.7, 'recall': 1.0, 'f1-score': 0.8235, 'support': 14}\n",
      "\n",
      "üîÅ Fold 4\n",
      "Accuracy: 0.9936\n",
      "Confusion Matrix:\n",
      "[[298   1]\n",
      " [  1  13]]\n",
      "Per-class Metrics:\n",
      "  Class 0: {'precision': 0.9967, 'recall': 0.9967, 'f1-score': 0.9967, 'support': 299}\n",
      "  Class 1: {'precision': 0.9286, 'recall': 0.9286, 'f1-score': 0.9286, 'support': 14}\n",
      "\n",
      "üîÅ Fold 5\n",
      "Accuracy: 0.9968\n",
      "Confusion Matrix:\n",
      "[[297   1]\n",
      " [  0  14]]\n",
      "Per-class Metrics:\n",
      "  Class 0: {'precision': 1.0, 'recall': 0.9966, 'f1-score': 0.9983, 'support': 298}\n",
      "  Class 1: {'precision': 0.9333, 'recall': 1.0, 'f1-score': 0.9655, 'support': 14}\n",
      "\n",
      "üìä 5-Fold Cross-Validation Summary:\n",
      "Average Accuracy: 0.9891\n",
      "\n",
      "üìà Average Per-Class Metrics (across 5 folds):\n",
      "  Class 0: {'precision': 0.9987, 'recall': 0.9899, 'f1-score': 0.9943}\n",
      "  Class 1: {'precision': 0.8347, 'recall': 0.9724, 'f1-score': 0.8949}\n",
      "\n",
      "‚úÖ Random Forest (cross-validated) model saved as 'random_forest_anomaly_model_cv.pkl'.\n",
      "\n",
      "üßÆ Average Confusion Matrix (across 5 folds):\n",
      "[[296   3]\n",
      " [  0  14]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"labeled_thermal_features.csv\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=[\"Frame\", \"Porosity Label\"])\n",
    "y = df[\"Porosity Label\"]\n",
    "\n",
    "# Initialize 5-fold CV\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store metrics\n",
    "accuracies = []\n",
    "conf_matrices = []\n",
    "class_metrics = []  # list of dicts to store class-wise scores\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(f\"\\nüîÅ Fold {fold}\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE(sampling_strategy=0.2, random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Initialize classifier\n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        max_features=\"sqrt\",\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    rf_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Collect detailed metrics per class\n",
    "    per_class = {\n",
    "        label: {\n",
    "            \"precision\": round(metrics[\"precision\"], 4),\n",
    "            \"recall\": round(metrics[\"recall\"], 4),\n",
    "            \"f1-score\": round(metrics[\"f1-score\"], 4),\n",
    "            \"support\": int(metrics[\"support\"])\n",
    "        }\n",
    "        for label, metrics in report_dict.items()\n",
    "        if label in ['0', '1']  # assuming binary classification (normal: 0, anomaly: 1)\n",
    "    }\n",
    "    class_metrics.append(per_class)\n",
    "    accuracies.append(accuracy)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "    # Print fold-wise results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Per-class Metrics:\")\n",
    "    for label, scores in per_class.items():\n",
    "        print(f\"  Class {label}: {scores}\")\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# =========================\n",
    "# üìä Final Summary\n",
    "# =========================\n",
    "print(\"\\nüìä 5-Fold Cross-Validation Summary:\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
    "\n",
    "# Aggregate F1-scores across folds\n",
    "avg_metrics = {\n",
    "    \"0\": {\"precision\": 0, \"recall\": 0, \"f1-score\": 0},\n",
    "    \"1\": {\"precision\": 0, \"recall\": 0, \"f1-score\": 0}\n",
    "}\n",
    "\n",
    "for class_stat in class_metrics:\n",
    "    for label in [\"0\", \"1\"]:\n",
    "        for metric in [\"precision\", \"recall\", \"f1-score\"]:\n",
    "            avg_metrics[label][metric] += class_stat[label][metric]\n",
    "\n",
    "# Average over 5 folds\n",
    "for label in [\"0\", \"1\"]:\n",
    "    for metric in [\"precision\", \"recall\", \"f1-score\"]:\n",
    "        avg_metrics[label][metric] /= 5\n",
    "        avg_metrics[label][metric] = round(avg_metrics[label][metric], 4)\n",
    "\n",
    "print(\"\\nüìà Average Per-Class Metrics (across 5 folds):\")\n",
    "for label, scores in avg_metrics.items():\n",
    "    print(f\"  Class {label}: {scores}\")\n",
    "\n",
    "# Save last model\n",
    "with open(\"random_forest_anomaly_model_cv.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(rf_classifier, model_file)\n",
    "\n",
    "print(\"\\n‚úÖ Random Forest (cross-validated) model saved as 'random_forest_anomaly_model_cv.pkl'.\")\n",
    "\n",
    "# Compute average confusion matrix\n",
    "sum_conf_matrix = np.sum(conf_matrices, axis=0)\n",
    "avg_conf_matrix = sum_conf_matrix / 5\n",
    "\n",
    "print(\"\\nüßÆ Average Confusion Matrix (across 5 folds):\")\n",
    "print(np.round(avg_conf_matrix).astype(int))  # or use .astype(float) if you want decimal values\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
